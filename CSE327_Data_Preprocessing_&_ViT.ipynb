{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVUQ_uPuan9s"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Prreprocessing\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/ICBHI_final_database\"\n",
        "data = []\n",
        "\n",
        "for fname in os.listdir(DATASET_DIR):\n",
        "    if fname.endswith(\".txt\"):\n",
        "        wav_name = fname.replace(\".txt\", \".wav\")\n",
        "        wav_path = os.path.join(DATASET_DIR, wav_name)\n",
        "\n",
        "        # skip non-existing .wav files\n",
        "        if not os.path.exists(wav_path):\n",
        "            continue\n",
        "\n",
        "        txt_path = os.path.join(DATASET_DIR, fname)\n",
        "        wheeze_vals = []\n",
        "        with open(txt_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 4:\n",
        "                    try:\n",
        "                        wheeze = int(parts[-1])\n",
        "                        wheeze_vals.append(wheeze)\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "\n",
        "        has_wheeze = int(any(wheeze_vals))\n",
        "        data.append((wav_name, has_wheeze))\n",
        "\n",
        "# DataFrame is buit\n",
        "df = pd.DataFrame(data, columns=[\"filename\", \"wheeze_label\"])\n",
        "df['full_path'] = df['filename'].apply(lambda x: os.path.join(DATASET_DIR, x))\n",
        "\n",
        "# Resaving is possible\n",
        "df.to_csv(\"/content/drive/MyDrive/wheeze_labels_filtered.csv\", index=False)"
      ],
      "metadata": {
        "id": "NRxGfcKVbHkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deinfe Initial ViT Model\n",
        "\n",
        "# Validation Accuracy: 0.7011\n",
        "# F1-score: 0.5926\n",
        "# ROC-AUC: 0.7276\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import librosa\n",
        "import timm\n",
        "\n",
        "# Config\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/ICBHI_final_database\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/wheeze_labels_filtered.csv\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load label CSV\n",
        "df = pd.read_csv(LABEL_PATH)\n",
        "df['full_path'] = df['filename'].apply(lambda x: os.path.join(AUDIO_DIR, x))\n",
        "\n",
        "# Train/Validation split\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['wheeze_label'], random_state=42)\n",
        "\n",
        "# Feature extractor\n",
        "def audio_to_logmel(filepath, sr=16000, n_fft=1024, hop_length=512, n_mels=128):\n",
        "    y, _ = librosa.load(filepath, sr=sr)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    return log_mel\n",
        "\n",
        "# Dataset class\n",
        "class RespiratoryDataset(Dataset):\n",
        "    def __init__(self, df, sr=16000):\n",
        "        self.df = df\n",
        "        self.sr = sr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        label = row['wheeze_label']\n",
        "        filepath = row['full_path']\n",
        "        log_mel = audio_to_logmel(filepath, sr=self.sr)\n",
        "\n",
        "        x = torch.tensor(log_mel).unsqueeze(0)  # (1, H, W)\n",
        "        x = torch.nn.functional.interpolate(x.unsqueeze(0), size=(224, 224), mode='bilinear').squeeze(0)\n",
        "        x = x.repeat(3, 1, 1)  # (3, 224, 224)\n",
        "\n",
        "        return x, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Loaders\n",
        "train_dataset = RespiratoryDataset(train_df)\n",
        "val_dataset = RespiratoryDataset(val_df)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Model: ViT without Sigmoid\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "model.head = nn.Linear(model.head.in_features, 1)  # remove Sigmoid\n",
        "model.to(device)\n",
        "\n",
        "# Weighted Loss\n",
        "label_counts = df['wheeze_label'].value_counts()\n",
        "neg, pos = label_counts[0], label_counts[1]\n",
        "pos_weight = torch.tensor([neg / pos]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop with validation\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        preds = model(X).view(-1)\n",
        "        loss = criterion(preds, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    preds_list, probs_list, targets_list = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            preds = model(X).view(-1)\n",
        "            loss = criterion(preds, y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(preds)\n",
        "            preds_list.extend((probs > 0.5).int().cpu().numpy())\n",
        "            probs_list.extend(probs.cpu().numpy())\n",
        "            targets_list.extend(y.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(targets_list, preds_list)\n",
        "    f1 = f1_score(targets_list, preds_list)\n",
        "    auc = roc_auc_score(targets_list, probs_list)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "1a3XPcsMbHh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vision Transformer with SpecAugment, Fine-Tuning, and 30 Epoch Training\n",
        "# SpecAugmentation Hyperparameter\n",
        "# freq_mask_param = 15\n",
        "# time_mask_param = 20\n",
        "\n",
        "# Validation Accuracy: 0.6522\n",
        "# F1-score: 0.6000\n",
        "# ROC-AUC: 0.7131\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio.transforms as T\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import timm\n",
        "\n",
        "# Configuration\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/ICBHI_final_database\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/wheeze_labels_filtered.csv\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load DataFrame with labels\n",
        "df = pd.read_csv(LABEL_PATH)\n",
        "df['full_path'] = df['filename'].apply(lambda x: os.path.join(AUDIO_DIR, x))\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['wheeze_label'], random_state=42)\n",
        "\n",
        "# Audio to Log-Mel Conversion\n",
        "def audio_to_logmel(filepath, sr=16000, n_fft=1024, hop_length=512, n_mels=128):\n",
        "    y, _ = librosa.load(filepath, sr=sr)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    return log_mel\n",
        "\n",
        "# Dataset with SpecAugment\n",
        "class RespiratoryDataset(Dataset):\n",
        "    def __init__(self, df, sr=16000, augment=False):\n",
        "        self.df = df\n",
        "        self.sr = sr\n",
        "        self.augment = augment\n",
        "        self.freq_mask = T.FrequencyMasking(freq_mask_param=15)\n",
        "        self.time_mask = T.TimeMasking(time_mask_param=20)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        filepath = row['full_path']\n",
        "        label = row['wheeze_label']\n",
        "        log_mel = audio_to_logmel(filepath, sr=self.sr)\n",
        "        x = torch.tensor(log_mel).unsqueeze(0)\n",
        "\n",
        "        if self.augment:\n",
        "            x = self.freq_mask(x)\n",
        "            x = self.time_mask(x)\n",
        "\n",
        "        x = torch.nn.functional.interpolate(x.unsqueeze(0), size=(224, 224), mode='bilinear').squeeze(0)\n",
        "        x = x.repeat(3, 1, 1)\n",
        "        return x, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Loaders\n",
        "train_dataset = RespiratoryDataset(train_df, augment=True)\n",
        "val_dataset = RespiratoryDataset(val_df, augment=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# ViT Model + Fine-tuning strategy\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "model.head = nn.Linear(model.head.in_features, 1)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for name, param in model.named_parameters():\n",
        "    if \"blocks.11\" in name or \"head\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Weighted Loss for imbalance\n",
        "label_counts = df['wheeze_label'].value_counts()\n",
        "neg, pos = label_counts[0], label_counts[1]\n",
        "pos_weight = torch.tensor([neg / pos]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
        "\n",
        "# Training Loop (30 epochs)\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        preds = model(X).view(-1)\n",
        "        loss = criterion(preds, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    preds_list, probs_list, targets_list = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            preds = model(X).view(-1)\n",
        "            loss = criterion(preds, y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(preds)\n",
        "            preds_list.extend((probs > 0.5).int().cpu().numpy())\n",
        "            probs_list.extend(probs.cpu().numpy())\n",
        "            targets_list.extend(y.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(targets_list, preds_list)\n",
        "    f1 = f1_score(targets_list, preds_list)\n",
        "    auc = roc_auc_score(targets_list, probs_list)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/50 | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "a3S6nrXLcwJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vision Transformer with SpecAugment, Fine-Tuning, and 30 Epoch Training\n",
        "# SpecAugmentation Hyperparameter\n",
        "# freq_mask_param = 20\n",
        "# time_mask_param = 60\n",
        "\n",
        "# Validation Accuracy: 0.5707\n",
        "# F1-score: 0.5093\n",
        "# ROC-AUC: 0.5766\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio.transforms as T\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import timm\n",
        "\n",
        "# Configuration\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/ICBHI_final_database\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/wheeze_labels_filtered.csv\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load DataFrame with labels\n",
        "df = pd.read_csv(LABEL_PATH)\n",
        "df['full_path'] = df['filename'].apply(lambda x: os.path.join(AUDIO_DIR, x))\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['wheeze_label'], random_state=42)\n",
        "\n",
        "# Audio to Log-Mel Conversion\n",
        "def audio_to_logmel(filepath, sr=16000, n_fft=1024, hop_length=512, n_mels=128):\n",
        "    y, _ = librosa.load(filepath, sr=sr)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    return log_mel\n",
        "\n",
        "# Dataset with SpecAugment\n",
        "class RespiratoryDataset(Dataset):\n",
        "    def __init__(self, df, sr=16000, augment=False):\n",
        "        self.df = df\n",
        "        self.sr = sr\n",
        "        self.augment = augment\n",
        "        self.freq_mask = T.FrequencyMasking(freq_mask_param=20)\n",
        "        self.time_mask = T.TimeMasking(time_mask_param=60)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        filepath = row['full_path']\n",
        "        label = row['wheeze_label']\n",
        "        log_mel = audio_to_logmel(filepath, sr=self.sr)\n",
        "        x = torch.tensor(log_mel).unsqueeze(0)\n",
        "\n",
        "        if self.augment:\n",
        "            x = self.freq_mask(x)\n",
        "            x = self.time_mask(x)\n",
        "\n",
        "        x = torch.nn.functional.interpolate(x.unsqueeze(0), size=(224, 224), mode='bilinear').squeeze(0)\n",
        "        x = x.repeat(3, 1, 1)\n",
        "        return x, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Loaders\n",
        "train_dataset = RespiratoryDataset(train_df, augment=True)\n",
        "val_dataset = RespiratoryDataset(val_df, augment=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# ViT Model + Fine-tuning strategy\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "model.head = nn.Linear(model.head.in_features, 1)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for name, param in model.named_parameters():\n",
        "    if \"blocks.11\" in name or \"head\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Weighted Loss for imbalance\n",
        "label_counts = df['wheeze_label'].value_counts()\n",
        "neg, pos = label_counts[0], label_counts[1]\n",
        "pos_weight = torch.tensor([neg / pos]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
        "\n",
        "# Training Loop (50 epochs)\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        preds = model(X).view(-1)\n",
        "        loss = criterion(preds, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    preds_list, probs_list, targets_list = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            preds = model(X).view(-1)\n",
        "            loss = criterion(preds, y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(preds)\n",
        "            preds_list.extend((probs > 0.5).int().cpu().numpy())\n",
        "            probs_list.extend(probs.cpu().numpy())\n",
        "            targets_list.extend(y.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(targets_list, preds_list)\n",
        "    f1 = f1_score(targets_list, preds_list)\n",
        "    auc = roc_auc_score(targets_list, probs_list)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/50 | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "LFE2LYbfepjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vision Transformer with SpecAugment, Fine-Tuning, and 30 Epoch Training\n",
        "# SpecAugmentation Hyperparameter\n",
        "# freq_mask_param = 0\n",
        "# time_mask_param = 0\n",
        "\n",
        "# Validation Accuracy: 0.6413\n",
        "# F1-score: 0.5769\n",
        "# ROC-AUC: 0.7134\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio.transforms as T\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import timm\n",
        "\n",
        "# Configuration\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/ICBHI_final_database\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/wheeze_labels_filtered.csv\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load DataFrame with labels\n",
        "df = pd.read_csv(LABEL_PATH)\n",
        "df['full_path'] = df['filename'].apply(lambda x: os.path.join(AUDIO_DIR, x))\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['wheeze_label'], random_state=42)\n",
        "\n",
        "# Audio to Log-Mel Conversion\n",
        "def audio_to_logmel(filepath, sr=16000, n_fft=1024, hop_length=512, n_mels=128):\n",
        "    y, _ = librosa.load(filepath, sr=sr)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    return log_mel\n",
        "\n",
        "# Dataset with SpecAugment\n",
        "class RespiratoryDataset(Dataset):\n",
        "    def __init__(self, df, sr=16000, augment=False):\n",
        "        self.df = df\n",
        "        self.sr = sr\n",
        "        self.augment = augment\n",
        "        self.freq_mask = T.FrequencyMasking(freq_mask_param=0)\n",
        "        self.time_mask = T.TimeMasking(time_mask_param=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        filepath = row['full_path']\n",
        "        label = row['wheeze_label']\n",
        "        log_mel = audio_to_logmel(filepath, sr=self.sr)\n",
        "        x = torch.tensor(log_mel).unsqueeze(0)\n",
        "\n",
        "        if self.augment:\n",
        "            x = self.freq_mask(x)\n",
        "            x = self.time_mask(x)\n",
        "\n",
        "        x = torch.nn.functional.interpolate(x.unsqueeze(0), size=(224, 224), mode='bilinear').squeeze(0)\n",
        "        x = x.repeat(3, 1, 1)\n",
        "        return x, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Loaders\n",
        "train_dataset = RespiratoryDataset(train_df, augment=True)\n",
        "val_dataset = RespiratoryDataset(val_df, augment=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# ViT Model + Fine-tuning strategy\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "model.head = nn.Linear(model.head.in_features, 1)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for name, param in model.named_parameters():\n",
        "    if \"blocks.11\" in name or \"head\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Weighted Loss for imbalance\n",
        "label_counts = df['wheeze_label'].value_counts()\n",
        "neg, pos = label_counts[0], label_counts[1]\n",
        "pos_weight = torch.tensor([neg / pos]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
        "\n",
        "# Training Loop (50 epochs)\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        preds = model(X).view(-1)\n",
        "        loss = criterion(preds, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    preds_list, probs_list, targets_list = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            preds = model(X).view(-1)\n",
        "            loss = criterion(preds, y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(preds)\n",
        "            preds_list.extend((probs > 0.5).int().cpu().numpy())\n",
        "            probs_list.extend(probs.cpu().numpy())\n",
        "            targets_list.extend(y.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(targets_list, preds_list)\n",
        "    f1 = f1_score(targets_list, preds_list)\n",
        "    auc = roc_auc_score(targets_list, probs_list)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/50 | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "sE-nfb1iwJCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vision Transformer with SpecAugment, Fine-Tuning, and 30 Epoch Training\n",
        "# SpecAugmentation Hyperparameter\n",
        "# freq_mask_param = 3\n",
        "# time_mask_param = 6\n",
        "\n",
        "# Validation Accuracy: 0.6169\n",
        "# F1-score: 0.6169\n",
        "# ROC-AUC: 0.7468\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio.transforms as T\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import timm\n",
        "\n",
        "# Configuration\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/ICBHI_final_database\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/wheeze_labels_filtered.csv\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load DataFrame with labels\n",
        "df = pd.read_csv(LABEL_PATH)\n",
        "df['full_path'] = df['filename'].apply(lambda x: os.path.join(AUDIO_DIR, x))\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['wheeze_label'], random_state=42)\n",
        "\n",
        "# Audio to Log-Mel Conversion\n",
        "def audio_to_logmel(filepath, sr=16000, n_fft=1024, hop_length=512, n_mels=128):\n",
        "    y, _ = librosa.load(filepath, sr=sr)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    return log_mel\n",
        "\n",
        "# Dataset with SpecAugment\n",
        "class RespiratoryDataset(Dataset):\n",
        "    def __init__(self, df, sr=16000, augment=False):\n",
        "        self.df = df\n",
        "        self.sr = sr\n",
        "        self.augment = augment\n",
        "        self.freq_mask = T.FrequencyMasking(freq_mask_param=3)\n",
        "        self.time_mask = T.TimeMasking(time_mask_param=6)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        filepath = row['full_path']\n",
        "        label = row['wheeze_label']\n",
        "        log_mel = audio_to_logmel(filepath, sr=self.sr)\n",
        "        x = torch.tensor(log_mel).unsqueeze(0)\n",
        "\n",
        "        if self.augment:\n",
        "            x = self.freq_mask(x)\n",
        "            x = self.time_mask(x)\n",
        "\n",
        "        x = torch.nn.functional.interpolate(x.unsqueeze(0), size=(224, 224), mode='bilinear').squeeze(0)\n",
        "        x = x.repeat(3, 1, 1)\n",
        "        return x, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Loaders\n",
        "train_dataset = RespiratoryDataset(train_df, augment=True)\n",
        "val_dataset = RespiratoryDataset(val_df, augment=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# ViT Model + Fine-tuning strategy\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "model.head = nn.Linear(model.head.in_features, 1)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for name, param in model.named_parameters():\n",
        "    if \"blocks.11\" in name or \"head\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Weighted Loss for imbalance\n",
        "label_counts = df['wheeze_label'].value_counts()\n",
        "neg, pos = label_counts[0], label_counts[1]\n",
        "pos_weight = torch.tensor([neg / pos]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
        "\n",
        "# Training Loop (50 epochs)\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        preds = model(X).view(-1)\n",
        "        loss = criterion(preds, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    preds_list, probs_list, targets_list = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            preds = model(X).view(-1)\n",
        "            loss = criterion(preds, y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(preds)\n",
        "            preds_list.extend((probs > 0.5).int().cpu().numpy())\n",
        "            probs_list.extend(probs.cpu().numpy())\n",
        "            targets_list.extend(y.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(targets_list, preds_list)\n",
        "    f1 = f1_score(targets_list, preds_list)\n",
        "    auc = roc_auc_score(targets_list, probs_list)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/50 | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "obi_P6GYzXIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vision Transformer with SpecAugment, Fine-Tuning, and 30 Epoch Training\n",
        "# SpecAugmentation Hyperparameter\n",
        "# freq_mask_param = 8\n",
        "# time_mask_param = 12\n",
        "\n",
        "# Validation Accuracy: 0.0.7174\n",
        "# F1-score: 0.5938\n",
        "# ROC-AUC: 0.7134\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio.transforms as T\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import timm\n",
        "\n",
        "# Configuration\n",
        "AUDIO_DIR = \"/content/drive/MyDrive/ICBHI_final_database\"\n",
        "LABEL_PATH = \"/content/drive/MyDrive/wheeze_labels_filtered.csv\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load DataFrame with labels\n",
        "df = pd.read_csv(LABEL_PATH)\n",
        "df['full_path'] = df['filename'].apply(lambda x: os.path.join(AUDIO_DIR, x))\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['wheeze_label'], random_state=42)\n",
        "\n",
        "# Audio to Log-Mel Conversion\n",
        "def audio_to_logmel(filepath, sr=16000, n_fft=1024, hop_length=512, n_mels=128):\n",
        "    y, _ = librosa.load(filepath, sr=sr)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
        "    return log_mel\n",
        "\n",
        "# Dataset with SpecAugment\n",
        "class RespiratoryDataset(Dataset):\n",
        "    def __init__(self, df, sr=16000, augment=False):\n",
        "        self.df = df\n",
        "        self.sr = sr\n",
        "        self.augment = augment\n",
        "        self.freq_mask = T.FrequencyMasking(freq_mask_param=3)\n",
        "        self.time_mask = T.TimeMasking(time_mask_param=6)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        filepath = row['full_path']\n",
        "        label = row['wheeze_label']\n",
        "        log_mel = audio_to_logmel(filepath, sr=self.sr)\n",
        "        x = torch.tensor(log_mel).unsqueeze(0)\n",
        "\n",
        "        if self.augment:\n",
        "            x = self.freq_mask(x)\n",
        "            x = self.time_mask(x)\n",
        "\n",
        "        x = torch.nn.functional.interpolate(x.unsqueeze(0), size=(224, 224), mode='bilinear').squeeze(0)\n",
        "        x = x.repeat(3, 1, 1)\n",
        "        return x, torch.tensor(label, dtype=torch.float32)\n",
        "\n",
        "# Loaders\n",
        "train_dataset = RespiratoryDataset(train_df, augment=True)\n",
        "val_dataset = RespiratoryDataset(val_df, augment=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# ViT Model + Fine-tuning strategy\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "model.head = nn.Linear(model.head.in_features, 1)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for name, param in model.named_parameters():\n",
        "    if \"blocks.11\" in name or \"head\" in name:\n",
        "        param.requires_grad = True\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Weighted Loss for imbalance\n",
        "label_counts = df['wheeze_label'].value_counts()\n",
        "neg, pos = label_counts[0], label_counts[1]\n",
        "pos_weight = torch.tensor([neg / pos]).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
        "\n",
        "# Training Loop (50 epochs)\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        preds = model(X).view(-1)\n",
        "        loss = criterion(preds, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    preds_list, probs_list, targets_list = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            preds = model(X).view(-1)\n",
        "            loss = criterion(preds, y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(preds)\n",
        "            preds_list.extend((probs > 0.5).int().cpu().numpy())\n",
        "            probs_list.extend(probs.cpu().numpy())\n",
        "            targets_list.extend(y.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(targets_list, preds_list)\n",
        "    f1 = f1_score(targets_list, preds_list)\n",
        "    auc = roc_auc_score(targets_list, probs_list)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/50 | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n"
      ],
      "metadata": {
        "id": "qH_xjLdLzjVJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}